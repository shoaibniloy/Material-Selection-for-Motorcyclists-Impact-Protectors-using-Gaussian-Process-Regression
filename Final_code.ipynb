{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2df1sN-ePSgp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C, WhiteKernel\n",
        "from sklearn.model_selection import GridSearchCV, learning_curve\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import shap\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the updated training and test datasets\n",
        "training_data_path = 'training_data.csv'  # Adjust file path as needed\n",
        "test_data_path = 'test_data.csv'  # Adjust file path as needed\n",
        "\n",
        "# Load the datasets\n",
        "training_data = pd.read_csv(training_data_path)\n",
        "test_data = pd.read_csv(test_data_path)\n",
        "\n",
        "# Clean the data: Remove commas from Force columns and convert them to float\n",
        "training_data['Force (N)'] = training_data['Force (N)'].replace({',': ''}, regex=True).astype(float)\n",
        "test_data['Predicted Force (N)'] = test_data['Predicted Force (N)'].replace({',': ''}, regex=True).astype(float)\n",
        "\n",
        "# Prepare the training data\n",
        "X_train = training_data[['Density (log transformation)', 'Elasticity (Pa)', 'Tensile Stress (Pa)', 'Thickness (mm)']]\n",
        "y_train = training_data['Force (N)']\n",
        "\n",
        "# Prepare the test data\n",
        "X_test = test_data[['Density (log transformation)', 'Elasticity (Pa)', 'Tensile Stress (Pa)', 'Thickness (mm)']]\n",
        "\n",
        "# Create polynomial features\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_train_poly = poly.fit_transform(X_train)\n",
        "X_test_poly = poly.transform(X_test)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_poly = scaler.fit_transform(X_train_poly)\n",
        "X_test_poly = scaler.transform(X_test_poly)\n",
        "\n",
        "# Define the Gaussian Process Regressor with an RBF kernel\n",
        "kernel = C(1.0, (1e-3, 1e1)) * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e1)) + WhiteKernel(noise_level=1e-5, noise_level_bounds=(1e-10, 1e1))\n",
        "\n",
        "gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, random_state=42)\n",
        "\n",
        "# Hyperparameter grid search\n",
        "param_grid = {\n",
        "    'alpha': [1e-2, 1e-3, 1e-4, 1e-5],\n",
        "    'kernel__k1__k1__constant_value': [0.1, 1, 10, 100],\n",
        "    'kernel__k1__k2__length_scale': [0.1, 1, 10, 100]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(gpr, param_grid, cv=10, scoring='neg_mean_squared_error')\n",
        "grid_search.fit(X_train_poly, y_train)\n",
        "\n",
        "# Get the best model\n",
        "best_gpr = grid_search.best_estimator_\n",
        "\n",
        "# Predict the Force (N) values for the test data\n",
        "predicted_forces = best_gpr.predict(X_test_poly)\n",
        "\n",
        "# Add the predicted forces to the test data\n",
        "test_data['Predicted Force (N)'] = predicted_forces"
      ]
    }
  ]
}